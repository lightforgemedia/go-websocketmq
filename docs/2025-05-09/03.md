Okay, I will now proceed to update the Go test files. I'll start with the unit tests for the broker, then integration tests, and finally the E2E (Rod-based) tests. I will use `testify/assert` and `testify/require` for assertions.

**File: pkg/broker/ps/testutil/test_utils.go**
```go
// pkg/broker/ps/testutil/test_utils.go
package testutil

import (
	"fmt"
	"testing"
)

// TestLogger implements the websocketmq.Logger interface for testing purposes.
// It wraps testing.TB (which can be *testing.T or *testing.B) to log messages
// appropriately within the test execution context.
type TestLogger struct {
	t testing.TB
}

// NewTestLogger creates a new TestLogger instance.
func NewTestLogger(t testing.TB) *TestLogger {
	return &TestLogger{t: t}
}

// Debug logs a debug message using t.Logf, prefixed with "DEBUG: ".
func (l *TestLogger) Debug(msg string, args ...any) {
	l.t.Helper() // Marks this function as a test helper
	l.t.Logf("DEBUG: "+msg, args...)
}

// Info logs an informational message using t.Logf, prefixed with "INFO: ".
func (l *TestLogger) Info(msg string, args ...any) {
	l.t.Helper()
	l.t.Logf("INFO: "+msg, args...)
}

// Warn logs a warning message using t.Logf, prefixed with "WARN: ".
func (l *TestLogger) Warn(msg string, args ...any) {
	l.t.Helper()
	l.t.Logf("WARN: "+msg, args...)
}

// Error logs an error message using t.Errorf, prefixed with "ERROR: ".
// t.Errorf will also mark the test as failed.
func (l *TestLogger) Error(msg string, args ...any) {
	l.t.Helper()
	// Create the formatted message first to pass a single string to t.Errorf,
	// which then doesn't try to re-format.
	formattedMsg := fmt.Sprintf("ERROR: "+msg, args...)
	l.t.Error(formattedMsg) // This will mark the test as failed
}
```

**File: pkg/broker/ps/broker_test.go**
```go
// pkg/broker/ps/broker_test.go
package ps_test

import (
	"context"
	"errors"
	"fmt"
	"sync"
	"testing"
	"time"

	"github.com/lightforgemedia/go-websocketmq/pkg/broker"
	"github.com/lightforgemedia/go-websocketmq/pkg/broker/ps" // Testing the ps implementation
	"github.com/lightforgemedia/go-websocketmq/pkg/broker/ps/testutil"
	"github.com/lightforgemedia/go-websocketmq/pkg/model"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// MockConnectionWriter for testing broker's interaction with connections
type MockConnectionWriter struct {
	BrokerIDVal    string
	WriteMessageFn func(ctx context.Context, msg *model.Message) error
	CloseFn        func() error
	writeMu        sync.Mutex
	closed         bool
	MessagesWritten []*model.Message
}

func NewMockConnectionWriter(brokerID string) *MockConnectionWriter {
	return &MockConnectionWriter{
		BrokerIDVal: brokerID,
		MessagesWritten: make([]*model.Message, 0),
	}
}

func (m *MockConnectionWriter) WriteMessage(ctx context.Context, msg *model.Message) error {
	m.writeMu.Lock()
	defer m.writeMu.Unlock()
	if m.closed {
		return broker.ErrConnectionWrite // Simulate connection closed
	}
	m.MessagesWritten = append(m.MessagesWritten, msg)
	if m.WriteMessageFn != nil {
		return m.WriteMessageFn(ctx, msg)
	}
	return nil
}

func (m *MockConnectionWriter) BrokerClientID() string {
	return m.BrokerIDVal
}

func (m *MockConnectionWriter) Close() error {
	m.writeMu.Lock()
	m.closed = true
	m.writeMu.Unlock()
	if m.CloseFn != nil {
		return m.CloseFn()
	}
	return nil
}
func (m *MockConnectionWriter) GetWrittenMessages() []*model.Message {
    m.writeMu.Lock()
    defer m.writeMu.Unlock()
    // Return a copy to avoid race conditions if the caller modifies the slice
    // and to ensure thread safety if MessagesWritten is appended to concurrently
    // (though in typical test usage, GetWrittenMessages is called after operations).
    msgs := make([]*model.Message, len(m.MessagesWritten))
    copy(msgs, m.MessagesWritten)
    return msgs
}


// TestPubSubBroker_Publish_Event tests publishing events to subscribed handlers.
func TestPubSubBroker_Publish_Event(t *testing.T) {
	logger := testutil.NewTestLogger(t)
	b := ps.New(logger, broker.DefaultOptions())
	defer b.Close()

	topic := "event.test"
	payload := map[string]string{"data": "event_payload"}
	eventMsg := model.NewEvent(topic, payload)

	t.Run("single subscriber", func(t *testing.T) {
		received := make(chan *model.Message, 1)
		err := b.Subscribe(context.Background(), topic, func(ctx context.Context, msg *model.Message, _ string) (*model.Message, error) {
			received <- msg
			return nil, nil
		})
		require.NoError(t, err)

		err = b.Publish(context.Background(), eventMsg)
		require.NoError(t, err)

		select {
		case msg := <-received:
			assert.Equal(t, eventMsg.Header.MessageID, msg.Header.MessageID)
			assert.Equal(t, payload, msg.Body.(map[string]interface{}))
		case <-time.After(1 * time.Second):
			t.Fatal("timed out waiting for event")
		}
	})

	t.Run("multiple subscribers", func(t *testing.T) {
		var wg sync.WaitGroup
		numSubscribers := 3
		wg.Add(numSubscribers)
		receivedCount := 0
		var mu sync.Mutex

		for i := 0; i < numSubscribers; i++ {
			err := b.Subscribe(context.Background(), topic, func(ctx context.Context, msg *model.Message, _ string) (*model.Message, error) {
				mu.Lock()
				receivedCount++
				mu.Unlock()
				wg.Done()
				return nil, nil
			})
			require.NoError(t, err)
		}

		err := b.Publish(context.Background(), eventMsg)
		require.NoError(t, err)

		done := make(chan struct{})
		go func() { wg.Wait(); close(done) }()

		select {
		case <-done:
			assert.Equal(t, numSubscribers, receivedCount)
		case <-time.After(1 * time.Second):
			t.Fatal("timed out waiting for all subscribers")
		}
	})

	t.Run("no subscribers", func(t *testing.T) {
		unsubscribedTopic := "event.none"
		err := b.Publish(context.Background(), model.NewEvent(unsubscribedTopic, "data"))
		require.NoError(t, err) // Should not error
	})
}

// TestPubSubBroker_Publish_ResponseError tests publishing responses/errors to internal bus.
func TestPubSubBroker_Publish_ResponseError(t *testing.T) {
	logger := testutil.NewTestLogger(t)
	b := ps.New(logger, broker.DefaultOptions())
	defer b.Close()

	corrID := model.RandomID()
	respMsg := model.NewResponse(&model.Message{Header: model.MessageHeader{CorrelationID: corrID}}, "response_data")
	errMsg := model.NewErrorMessage(&model.Message{Header: model.MessageHeader{CorrelationID: corrID}}, "error_data")

	// Use internalBus.SubOnce to check if message arrives on CorrelationID topic
	respCh := b.(*ps.PubSubBroker).GetInternalBusForTest().SubOnce(corrID) // Helper to access internalBus for test
	defer b.(*ps.PubSubBroker).GetInternalBusForTest().Unsub(respCh)

	err := b.Publish(context.Background(), respMsg)
	require.NoError(t, err)

	select {
	case rawData := <-respCh:
		var receivedMsg model.Message
		err = json.Unmarshal(rawData.([]byte), &receivedMsg)
		require.NoError(t, err)
		assert.Equal(t, respMsg.Header.MessageID, receivedMsg.Header.MessageID)
		assert.Equal(t, "response_data", receivedMsg.Body)
	case <-time.After(1 * time.Second):
		t.Fatal("timed out waiting for response on internal bus")
	}

	// Test error message
	errCh := b.(*ps.PubSubBroker).GetInternalBusForTest().SubOnce(corrID)
	defer b.(*ps.PubSubBroker).GetInternalBusForTest().Unsub(errCh)

	err = b.Publish(context.Background(), errMsg)
	require.NoError(t, err)

	select {
	case rawData := <-errCh:
		var receivedMsg model.Message
		err = json.Unmarshal(rawData.([]byte), &receivedMsg)
		require.NoError(t, err)
		assert.Equal(t, errMsg.Header.MessageID, receivedMsg.Header.MessageID)
		assert.Equal(t, "error_data", receivedMsg.Body)
	case <-time.After(1 * time.Second):
		t.Fatal("timed out waiting for error on internal bus")
	}
}

// TestPubSubBroker_Subscribe_Lifecycle tests subscription and context cancellation.
func TestPubSubBroker_Subscribe_Lifecycle(t *testing.T) {
	logger := testutil.NewTestLogger(t)
	b := ps.New(logger, broker.DefaultOptions())
	defer b.Close()

	topic := "sub.lifecycle"
	handlerCalls := 0
	var mu sync.Mutex

	subCtx, cancelSub := context.WithCancel(context.Background())

	err := b.Subscribe(subCtx, topic, func(ctx context.Context, msg *model.Message, _ string) (*model.Message, error) {
		mu.Lock()
		handlerCalls++
		mu.Unlock()
		return nil, nil
	})
	require.NoError(t, err)

	// Publish, handler should be called
	err = b.Publish(context.Background(), model.NewEvent(topic, "data1"))
	require.NoError(t, err)
	time.Sleep(50 * time.Millisecond) // Allow async handler to run
	assert.Equal(t, 1, handlerCalls, "handler should be called once")

	// Cancel subscription context
	cancelSub()
	time.Sleep(100 * time.Millisecond) // Allow cleanup goroutine to run

	// Publish again, handler should NOT be called
	err = b.Publish(context.Background(), model.NewEvent(topic, "data2"))
	require.NoError(t, err)
	time.Sleep(50 * time.Millisecond)
	assert.Equal(t, 1, handlerCalls, "handler should not be called after context cancellation")
}

// TestPubSubBroker_Request_ServerToHandler tests server-to-handler RPC.
func TestPubSubBroker_Request_ServerToHandler(t *testing.T) {
	logger := testutil.NewTestLogger(t)
	b := ps.New(logger, broker.DefaultOptions())
	defer b.Close()

	reqTopic := "rpc.server.handler"
	reqPayload := map[string]string{"question": "meaning of life"}
	respPayload := map[string]int{"answer": 42}

	err := b.Subscribe(context.Background(), reqTopic, func(ctx context.Context, msg *model.Message, _ string) (*model.Message, error) {
		assert.Equal(t, reqPayload, msg.Body.(map[string]interface{}))
		return model.NewResponse(msg, respPayload), nil
	})
	require.NoError(t, err)

	reqMsg := model.NewRequest(reqTopic, reqPayload, 1000)
	respMsg, err := b.Request(context.Background(), reqMsg, 1000)
	require.NoError(t, err)
	require.NotNil(t, respMsg)
	assert.Equal(t, model.KindResponse, respMsg.Header.Type)
	assert.Equal(t, reqMsg.Header.CorrelationID, respMsg.Header.CorrelationID)
	assert.Equal(t, respPayload, respMsg.Body.(map[string]interface{}))

	t.Run("handler returns error", func(t *testing.T) {
		errorTopic := "rpc.server.handler.error"
		errMsgText := "handler intentional error"
		err := b.Subscribe(context.Background(), errorTopic, func(ctx context.Context, msg *model.Message, _ string) (*model.Message, error) {
			return nil, errors.New(errMsgText)
		})
		require.NoError(t, err)

		reqMsgErr := model.NewRequest(errorTopic, "data", 1000)
		respMsgErr, err := b.Request(context.Background(), reqMsgErr, 1000)
		require.NoError(t, err) // Request itself doesn't fail, it gets an error response
		require.NotNil(t, respMsgErr)
		assert.Equal(t, model.KindError, respMsgErr.Header.Type)
		assert.Equal(t, reqMsgErr.Header.CorrelationID, respMsgErr.Header.CorrelationID)
		errBody, ok := respMsgErr.Body.(map[string]interface{})
		require.True(t, ok)
		assert.Contains(t, errBody["error"], errMsgText)
	})

	t.Run("request timeout", func(t *testing.T) {
		timeoutTopic := "rpc.server.handler.timeout"
		err := b.Subscribe(context.Background(), timeoutTopic, func(ctx context.Context, msg *model.Message, _ string) (*model.Message, error) {
			time.Sleep(200 * time.Millisecond) // Sleep longer than timeout
			return model.NewResponse(msg, "late response"), nil
		})
		require.NoError(t, err)

		reqMsgTimeout := model.NewRequest(timeoutTopic, "data", 100) // 100ms timeout
		_, err = b.Request(context.Background(), reqMsgTimeout, 100)
		require.Error(t, err)
		assert.ErrorIs(t, err, broker.ErrRequestTimeout)
	})

	t.Run("no handler for topic", func(t *testing.T) {
		noHandlerTopic := "rpc.server.handler.none"
		reqMsgNoHandler := model.NewRequest(noHandlerTopic, "data", 100)
		_, err := b.Request(context.Background(), reqMsgNoHandler, 100)
		require.Error(t, err)
		// This will timeout because no handler means no response will be published to the correlation ID
		assert.ErrorIs(t, err, broker.ErrRequestTimeout)
	})
}

// TestPubSubBroker_RequestToClient tests server-to-WebSocket client RPC.
func TestPubSubBroker_RequestToClient(t *testing.T) {
	logger := testutil.NewTestLogger(t)
	b := ps.New(logger, broker.DefaultOptions())
	defer b.Close()

	clientID := "client-rpc-target"
	mockConn := NewMockConnectionWriter(clientID)
	err := b.RegisterConnection(mockConn)
	require.NoError(t, err)

	reqTopic := "client.action.perform" // This is the "action name" client listens to
	reqPayload := map[string]string{"command": "do_something"}
	respPayload := map[string]string{"status": "done"}

	// Simulate client receiving request and sending response via broker.Publish
	mockConn.WriteMessageFn = func(ctx context.Context, msg *model.Message) error {
		// Client receives this request
		require.Equal(t, reqTopic, msg.Header.Topic)
		require.Equal(t, reqPayload, msg.Body.(map[string]interface{}))

		// Client processes and sends response
		clientResp := model.NewResponse(msg, respPayload)
		// Simulate client publishing response back to broker
		go func() {
			time.Sleep(10 * time.Millisecond) // Simulate network delay
			err := b.Publish(context.Background(), clientResp)
			assert.NoError(t, err, "Client failed to publish response")
		}()
		return nil
	}

	reqMsg := model.NewRequest(reqTopic, reqPayload, 1000)
	respMsg, err := b.RequestToClient(context.Background(), clientID, reqMsg, 1000)
	require.NoError(t, err)
	require.NotNil(t, respMsg)
	assert.Equal(t, model.KindResponse, respMsg.Header.Type)
	assert.Equal(t, reqMsg.Header.CorrelationID, respMsg.Header.CorrelationID)
	assert.Equal(t, respPayload, respMsg.Body.(map[string]interface{}))
	assert.Len(t, mockConn.GetWrittenMessages(), 1, "Expected 1 message written to client")
	assert.Equal(t, reqMsg.Header.MessageID, mockConn.GetWrittenMessages()[0].Header.MessageID)


	t.Run("client not found", func(t *testing.T) {
		_, err := b.RequestToClient(context.Background(), "nonexistent-client", model.NewRequest("topic", "data", 100), 100)
		require.Error(t, err)
		assert.ErrorIs(t, err, broker.ErrClientNotFound)
	})

	t.Run("client write error", func(t *testing.T) {
		errorClientID := "client-write-error"
		errorConn := NewMockConnectionWriter(errorClientID)
		errorConn.WriteMessageFn = func(ctx context.Context, msg *model.Message) error {
			return broker.ErrConnectionWrite // Simulate write failure
		}
		err := b.RegisterConnection(errorConn)
		require.NoError(t, err)

		_, err = b.RequestToClient(context.Background(), errorClientID, model.NewRequest("topic", "data", 100), 100)
		require.Error(t, err)
		assert.ErrorIs(t, err, broker.ErrConnectionWrite)
	})

	t.Run("client timeout", func(t *testing.T) {
		timeoutClientID := "client-timeout"
		timeoutConn := NewMockConnectionWriter(timeoutClientID)
		timeoutConn.WriteMessageFn = func(ctx context.Context, msg *model.Message) error {
			// Client receives but doesn't respond
			return nil
		}
		err := b.RegisterConnection(timeoutConn)
		require.NoError(t, err)
		
		_, err = b.RequestToClient(context.Background(), timeoutClientID, model.NewRequest("topic", "data", 100), 100) // 100ms timeout
		require.Error(t, err)
		assert.ErrorIs(t, err, broker.ErrRequestTimeout)
	})
}

// TestPubSubBroker_ConnectionManagement tests Register/DeregisterConnection.
func TestPubSubBroker_ConnectionManagement(t *testing.T) {
	logger := testutil.NewTestLogger(t)
	b := ps.New(logger, broker.DefaultOptions())
	defer b.Close()

	clientID := "conn-mgmt-client"
	mockConn := NewMockConnectionWriter(clientID)
	
	// Test GetConnection before registration
	_, found := b.(*ps.PubSubBroker).GetConnection(clientID)
	assert.False(t, found, "Connection should not be found before registration")

	err := b.RegisterConnection(mockConn)
	require.NoError(t, err)
	
	retrievedConn, found := b.(*ps.PubSubBroker).GetConnection(clientID)
	assert.True(t, found, "Connection should be found after registration")
	assert.Equal(t, mockConn, retrievedConn)

	// Test DeregisterConnection
	deregisteredEventReceived := make(chan *model.Message, 1)
	err = b.Subscribe(context.Background(), broker.TopicClientDeregistered, func(ctx context.Context, msg *model.Message, _ string) (*model.Message, error) {
		deregisteredEventReceived <- msg
		return nil, nil
	})
	require.NoError(t, err)

	var closeCalled bool
	mockConn.CloseFn = func() error { closeCalled = true; return nil }
	
	err = b.DeregisterConnection(clientID)
	require.NoError(t, err)
	assert.True(t, closeCalled, "ConnectionWriter.Close() should be called on deregister")

	_, found = b.(*ps.PubSubBroker).GetConnection(clientID)
	assert.False(t, found, "Connection should not be found after deregistration")

	select {
	case eventMsg := <-deregisteredEventReceived:
		assert.Equal(t, broker.TopicClientDeregistered, eventMsg.Header.Topic)
		body, ok := eventMsg.Body.(map[string]interface{}) // ps.PubSubBroker publishes map[string]string, json unmarshals to this
		require.True(t, ok)
		assert.Equal(t, clientID, body["brokerClientID"])
	case <-time.After(1 * time.Second):
		t.Fatal("timed out waiting for client deregistered event")
	}

	// Deregister non-existent
	err = b.DeregisterConnection("nonexistent-client")
	require.NoError(t, err) // Should not error
}


// TestPubSubBroker_Close tests broker shutdown behavior.
func TestPubSubBroker_Close(t *testing.T) {
	logger := testutil.NewTestLogger(t)
	b := ps.New(logger, broker.DefaultOptions())

	// Register a connection
	clientID := "client-to-close"
	mockConn := NewMockConnectionWriter(clientID)
	var connCloseCalled bool
	mockConn.CloseFn = func() error { connCloseCalled = true; return nil }
	err := b.RegisterConnection(mockConn)
	require.NoError(t, err)

	// Add a subscription
	subCtx, cancelSub := context.WithCancel(context.Background())
	var subHandlerCalled bool
	err = b.Subscribe(subCtx, "topic.close", func(ctx context.Context, msg *model.Message, _ string) (*model.Message, error) {
		subHandlerCalled = true
		return nil, nil
	})
	require.NoError(t, err)

	// Publish before close - should work
	err = b.Publish(context.Background(), model.NewEvent("topic.close", "data"))
	require.NoError(t, err)
	time.Sleep(50 * time.Millisecond)
	assert.True(t, subHandlerCalled, "Subscription handler should be called before broker close")

	// Close the broker
	err = b.Close()
	require.NoError(t, err)
	b.(*ps.PubSubBroker).WaitForShutdown() // Wait for full shutdown

	assert.True(t, connCloseCalled, "Registered connection's Close() should be called")
	
	// Check if subscription context was cancelled
	select {
	case <-subCtx.Done():
		// Expected: subscription context should be cancelled by broker Close
	default:
		t.Error("Subscription context should be cancelled after broker Close")
	}
	// To be absolutely sure, try to publish again. Handler should not be called.
	subHandlerCalled = false
	err = b.Publish(context.Background(), model.NewEvent("topic.close", "data_after_close"))
	assert.ErrorIs(t, err, broker.ErrBrokerClosed)
	time.Sleep(50 * time.Millisecond)
	assert.False(t, subHandlerCalled, "Subscription handler should NOT be called after broker close")


	// All operations after close should fail
	err = b.Publish(context.Background(), model.NewEvent("any.topic", "data"))
	assert.ErrorIs(t, err, broker.ErrBrokerClosed)

	err = b.Subscribe(context.Background(), "any.topic", func(ctx context.Context, msg *model.Message, _ string) (*model.Message, error) { return nil, nil })
	assert.ErrorIs(t, err, broker.ErrBrokerClosed)

	_, err = b.Request(context.Background(), model.NewRequest("any.topic", "data", 100), 100)
	assert.ErrorIs(t, err, broker.ErrBrokerClosed)

	_, err = b.RequestToClient(context.Background(), "any.client", model.NewRequest("any.topic", "data", 100), 100)
	assert.ErrorIs(t, err, broker.ErrBrokerClosed)

	err = b.RegisterConnection(NewMockConnectionWriter("another-client"))
	assert.ErrorIs(t, err, broker.ErrBrokerClosed)

	// Closing again should return ErrBrokerClosed
	err = b.Close()
	assert.ErrorIs(t, err, broker.ErrBrokerClosed)

	// Cancel the original subscription context manually (good practice, though broker.Close should handle it)
	cancelSub()
}

// Helper method for tests to access internalBus.
// This is NOT part of the broker.Broker interface.
// Add this to ps.PubSubBroker in ps.go:
// func (b *PubSubBroker) GetInternalBusForTest() *pubsub.PubSub { return b.internalBus }
// This is a common pattern for testing unexported fields.
// For now, I'll assume it's added to ps.go for the test to compile.
// If not, this specific test part (TestPubSubBroker_Publish_ResponseError) needs adjustment.

// In ps.go, add:
// func (b *PubSubBroker) GetInternalBusForTest() *pubsub.PubSub { return b.internalBus }
// For the test TestPubSubBroker_Publish_ResponseError to work.
// This is a test-only helper.
// (I've added this to the ps.go implementation I generated earlier)
```

I've updated `TestPubSubBroker_Publish_ResponseError` to reflect how one might test internal bus interactions if a test-only helper `GetInternalBusForTest()` is added to `ps.PubSubBroker`. If such a helper is not desired, that specific test would need to verify the behavior through `Request` or `RequestToClient` which use the internal bus.

Next, `pkg/broker/ps/integration_test.go`.

**File: pkg/broker/ps/integration_test.go**
```go
// pkg/broker/ps/integration_test.go
package ps_test

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"net/http"
	"net/http/httptest"
	"strings"
	"sync"
	"testing"
	"time"

	"github.com/lightforgemedia/go-websocketmq/pkg/broker"
	"github.com/lightforgemedia/go-websocketmq/pkg/broker/ps" // Testing the ps implementation
	"github.com/lightforgemedia/go-websocketmq/pkg/broker/ps/testutil"
	"github.com/lightforgemedia/go-websocketmq/pkg/model"
	"github.com/lightforgemedia/go-websocketmq/pkg/server"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"nhooyr.io/websocket"
)

// TestServer struct and NewTestServer remain largely the same as provided before,
// ensuring it uses the updated ps.New and server.NewHandler.

// TestClient struct and NewTestClient also remain largely the same,
// but its Connect, register, sendMessage, handleMessages, SendRPC, Close methods
// are refined for robustness and clarity.

// TestServer represents a WebSocketMQ server for testing
type TestServer struct {
	Server   *httptest.Server
	Broker   broker.Broker
	Handler  *server.Handler
	Logger   *testutil.TestLogger
	Ready    chan struct{}
	Shutdown chan struct{}
	Opts     broker.Options // Allow passing broker options
	HandlerOpts server.HandlerOptions // Allow passing handler options
}

// NewTestServer creates and starts a new test server
func NewTestServer(t *testing.T, opts ...interface{}) *TestServer {
	ts := &TestServer{
		Logger:   testutil.NewTestLogger(t),
		Ready:    make(chan struct{}),
		Shutdown: make(chan struct{}),
		Opts:     broker.DefaultOptions(), // Default broker options
		HandlerOpts: server.DefaultHandlerOptions(), // Default handler options
	}

	for _, opt := range opts {
		switch v := opt.(type) {
		case broker.Options:
			ts.Opts = v
		case server.HandlerOptions:
			ts.HandlerOpts = v
		default:
			t.Fatalf("Unsupported option type for NewTestServer: %T", v)
		}
	}
	
	// Ensure AllowedOrigins is set for testing simplicity if not provided
	if ts.HandlerOpts.AllowedOrigins == nil {
		ts.HandlerOpts.AllowedOrigins = []string{"*"} 
	}


	// Create broker
	ts.Broker = ps.New(ts.Logger, ts.Opts)

	// Create WebSocket handler
	ts.Handler = server.NewHandler(ts.Broker, ts.Logger, ts.HandlerOpts)

	// Create HTTP server
	mux := http.NewServeMux()
	mux.Handle("/ws", ts.Handler)

	// Start server
	ts.Server = httptest.NewServer(mux)

	// Signal that the server is ready
	close(ts.Ready)
	ts.Logger.Info("TestServer ready at %s", ts.Server.URL)
	return ts
}

// RegisterHandler registers an RPC handler on the server
func (ts *TestServer) RegisterHandler(topic string, handler broker.MessageHandler) error {
	return ts.Broker.Subscribe(context.Background(), topic, handler)
}

// SendRPCToClient sends an RPC request to a specific client
func (ts *TestServer) SendRPCToClient(ctx context.Context, clientID string, topic string, body interface{}, timeoutMs int64) (*model.Message, error) {
	req := model.NewRequest(topic, body, timeoutMs)
	return ts.Broker.RequestToClient(ctx, clientID, req, timeoutMs)
}

// Close shuts down the test server
func (ts *TestServer) Close() {
	ts.Logger.Info("Closing TestServer...")
	// Order: HTTP server, then broker
	if ts.Server != nil {
		ts.Server.Close()
	}
	if ts.Broker != nil {
		if err := ts.Broker.Close(); err != nil && !errors.Is(err, broker.ErrBrokerClosed) {
			ts.Logger.Error("Error closing broker: %v", err)
		}
		// Wait for broker shutdown if it's the ps.PubSubBroker
		if psb, ok := ts.Broker.(*ps.PubSubBroker); ok {
			psb.WaitForShutdown()
		}
	}
	close(ts.Shutdown) // Signal local shutdown complete
	ts.Logger.Info("TestServer closed.")
}

// TestClient represents a WebSocketMQ client for testing
type TestClient struct {
	Conn             *websocket.Conn
	URL              string
	PageSessionID    string
	BrokerClientID   string // Set by server upon registration ACK
	Logger           *testutil.TestLogger
	Connected        chan struct{}       // Closed when client considers itself connected and registered
	MessageReceived  chan *model.Message // For general message snooping or specific waits
	Closed           chan struct{}       // Closed when handleMessages exits
	Handlers         map[string]broker.MessageHandler // topic -> handler
	HandlersMutex    sync.RWMutex
	ResponseChannels map[string]chan *model.Message // correlationID -> chan *model.Message
	ResponseMutex    sync.RWMutex
	ctx              context.Context    // Overall context for the client's lifecycle
	cancel           context.CancelFunc // Cancels the client's context
	wg               sync.WaitGroup     // For waiting on handleMessages goroutine
	
	// Configurable topics, should match server.HandlerOptions
	ClientRegisterTopic      string 
	ClientRegisteredAckTopic string
}

// NewTestClient creates a new test client
func NewTestClient(t *testing.T, serverURL string, handlerOpts ...server.HandlerOptions) *TestClient {
	wsURL := strings.Replace(serverURL, "http://", "ws://", 1) + "/ws"
	ctx, cancel := context.WithCancel(context.Background())

	opts := server.DefaultHandlerOptions()
	if len(handlerOpts) > 0 {
		opts = handlerOpts[0]
	}


	tc := &TestClient{
		URL:                      wsURL,
		PageSessionID:            "test-page-session-" + model.RandomID(),
		Logger:                   testutil.NewTestLogger(t),
		Connected:                make(chan struct{}),
		MessageReceived:          make(chan *model.Message, 20), // Buffered
		Closed:                   make(chan struct{}),
		Handlers:                 make(map[string]broker.MessageHandler),
		ResponseChannels:         make(map[string]chan *model.Message),
		ctx:                      ctx,
		cancel:                   cancel,
		ClientRegisterTopic:      opts.ClientRegisterTopic,
		ClientRegisteredAckTopic: opts.ClientRegisteredAckTopic,
	}
	return tc
}

// Connect establishes a WebSocket connection to the server and registers.
func (tc *TestClient) Connect(ctx context.Context) error {
	tc.Logger.Debug("TestClient %s: Connecting to %s", tc.PageSessionID, tc.URL)
	var err error
	// Use a timeout for the dial operation itself, derived from the provided context
	dialCtx, dialCancel := context.WithTimeout(ctx, 10*time.Second) // Increased dial timeout
	defer dialCancel()

	tc.Conn, _, err = websocket.Dial(dialCtx, tc.URL, nil)
	if err != nil {
		return fmt.Errorf("TestClient %s: Failed to dial %s: %w", tc.PageSessionID, tc.URL, err)
	}
	tc.Logger.Debug("TestClient %s: WebSocket dialed successfully.", tc.PageSessionID)

	tc.wg.Add(1)
	go tc.handleMessages()

	// Subscribe to the registration ACK topic *before* sending registration
	var regAckOnce sync.Once
	tc.RegisterHandler(tc.ClientRegisteredAckTopic, func(handlerCtx context.Context, msg *model.Message, _ string) (*model.Message, error) {
		tc.Logger.Debug("TestClient %s: Received potential registration ACK on topic '%s': %+v", tc.PageSessionID, tc.ClientRegisteredAckTopic, msg.Body)
		
		bodyMap, ok := msg.Body.(map[string]interface{}) // Server sends map[string]string, json unmarshals to this
		if !ok {
			tc.Logger.Error("TestClient %s: Registration ACK body is not map[string]interface{}, got %T", tc.PageSessionID, msg.Body)
			return nil, nil
		}
		
		clientID, idOk := bodyMap["brokerClientID"].(string)
		pageID, pageOk := bodyMap["pageSessionID"].(string)

		if idOk && pageOk && pageID == tc.PageSessionID {
			regAckOnce.Do(func() {
				tc.BrokerClientID = clientID
				tc.Logger.Info("TestClient %s: Registered with BrokerClientID: %s", tc.PageSessionID, clientID)
				close(tc.Connected) // Signal successful connection and registration
			})
		} else {
			tc.Logger.Warn("TestClient %s: Received registration ACK, but brokerClientID missing or pageSessionID mismatch. Expected PageID: %s, Got: %+v", tc.PageSessionID, pageID, bodyMap)
		}
		return nil, nil // No response needed for this event
	})

	// Send registration message
	if err := tc.registerClient(ctx); err != nil {
		tc.Conn.Close(websocket.StatusInternalError, "registration send failed") // Best effort close
		return fmt.Errorf("TestClient %s: Sending registration message failed: %w", tc.PageSessionID, err)
	}
	tc.Logger.Debug("TestClient %s: Registration message sent.", tc.PageSessionID)
	return nil
}

// registerClient sends the client registration message.
func (tc *TestClient) registerClient(ctx context.Context) error {
	regMsg := model.NewEvent(tc.ClientRegisterTopic, map[string]string{ // Ensure map[string]string for server handler
		"pageSessionID": tc.PageSessionID,
	})
	return tc.sendMessage(ctx, regMsg)
}

// sendMessage sends a message to the server.
func (tc *TestClient) sendMessage(ctx context.Context, msg *model.Message) error {
	if tc.Conn == nil {
		return fmt.Errorf("TestClient %s: Connection is nil, cannot send message", tc.PageSessionID)
	}
	data, err := json.Marshal(msg)
	if err != nil {
		return fmt.Errorf("TestClient %s: Failed to marshal message %+v: %w", tc.PageSessionID, msg, err)
	}

	// Use a timeout for the write operation, derived from the provided context
	writeCtx, cancel := context.WithTimeout(ctx, 10*time.Second) // Generous write timeout
	defer cancel()
	
	err = tc.Conn.Write(writeCtx, websocket.MessageText, data)
	if err != nil {
		return fmt.Errorf("TestClient %s: Failed to write message to WebSocket: %w", tc.PageSessionID, err)
	}
	tc.Logger.Debug("TestClient %s: Sent message: Type=%s, Topic=%s, CorrID=%s", tc.PageSessionID, msg.Header.Type, msg.Header.Topic, msg.Header.CorrelationID)
	return nil
}

// handleMessages processes incoming messages from the server.
func (tc *TestClient) handleMessages() {
	defer tc.wg.Done()
	defer close(tc.Closed) // Signal that this goroutine has exited
	tc.Logger.Debug("TestClient %s: Starting message handler loop.", tc.PageSessionID)

	for {
		select {
		case <-tc.ctx.Done(): // If client's main context is cancelled
			tc.Logger.Debug("TestClient %s: Context done, exiting message handler loop.", tc.PageSessionID)
			return
		default:
			// Use a read timeout to allow periodic checks of tc.ctx.Done()
			readCtx, cancelRead := context.WithTimeout(tc.ctx, 5*time.Second)
			msgType, data, err := tc.Conn.Read(readCtx)
			cancelRead()

			if err != nil {
				if errors.Is(err, context.Canceled) || errors.Is(err, tc.ctx.Err()) { // Our context was cancelled
					tc.Logger.Debug("TestClient %s: Read context cancelled, exiting loop: %v", tc.PageSessionID, err)
					return
				}
				status := websocket.CloseStatus(err)
				if status == websocket.StatusNormalClosure || status == websocket.StatusGoingAway {
					tc.Logger.Info("TestClient %s: WebSocket closed normally or going away: %v (status: %d)", tc.PageSessionID, err, status)
					return
				}
				if errors.Is(err, context.DeadlineExceeded) { // This is the read timeout, normal, continue to check main ctx
					continue
				}
				// Other read errors are likely fatal for this connection
				tc.Logger.Error("TestClient %s: Unrecoverable error reading message: %v (status: %d)", tc.PageSessionID, err, status)
				return
			}

			if msgType != websocket.MessageText {
				tc.Logger.Warn("TestClient %s: Received non-text message type %v, ignoring.", tc.PageSessionID, msgType)
				continue
			}

			var msg model.Message
			if err := json.Unmarshal(data, &msg); err != nil {
				tc.Logger.Error("TestClient %s: Error unmarshaling message: %v. Data: %s", tc.PageSessionID, err, string(data))
				continue
			}
			tc.Logger.Debug("TestClient %s: Received message: Type=%s, Topic=%s, CorrID=%s",
				tc.PageSessionID, msg.Header.Type, msg.Header.Topic, msg.Header.CorrelationID)

			// Send to general snooping/wait channel
			select {
			case tc.MessageReceived <- &msg:
			case <-tc.ctx.Done(): // Don't block if context is done
				return
			default: // Don't block if buffer is full
				tc.Logger.Warn("TestClient %s: MessageReceived channel full or no listener, dropping message: Topic=%s", tc.PageSessionID, msg.Header.Topic)
			}

			// Route to specific handler or response channel
			isResponseOrError := msg.Header.Type == model.KindResponse || msg.Header.Type == model.KindError
			isRequest := msg.Header.Type == model.KindRequest

			// 1. Check if it's a response to a pending RPC
			if isResponseOrError && msg.Header.CorrelationID != "" {
				tc.ResponseMutex.RLock()
				ch, exists := tc.ResponseChannels[msg.Header.CorrelationID]
				tc.ResponseMutex.RUnlock()
				if exists {
					select {
					case ch <- &msg:
						tc.Logger.Debug("TestClient %s: Response for CorrID %s delivered to channel.", tc.PageSessionID, msg.Header.CorrelationID)
					case <-tc.ctx.Done():
						return
					default: // Should not happen if channel is buffered and consumed promptly
						tc.Logger.Warn("TestClient %s: Response channel full/closed for CorrID %s.", tc.PageSessionID, msg.Header.CorrelationID)
					}
					continue // Message handled as RPC response
				}
			}

			// 2. Check for registered handlers (for server-initiated requests or events)
			tc.HandlersMutex.RLock()
			handler, handlerExists := tc.Handlers[msg.Header.Topic]
			wildcardHandler, wildcardExists := tc.Handlers["#"] // Wildcard for all topics
			tc.HandlersMutex.RUnlock()

			dispatchedToSpecific := false
			if handlerExists {
				go tc.dispatchToHandler(&msg, handler) // Run handler in goroutine
				dispatchedToSpecific = true
			}
			if wildcardExists && (!handlerExists || msg.Header.Topic != "#") { // Avoid double call if specific also matched "#"
				go tc.dispatchToHandler(&msg, wildcardHandler)
				dispatchedToSpecific = true
			}
			
			if isRequest && !dispatchedToSpecific { // Server sent a request but client has no handler
				tc.Logger.Warn("TestClient %s: Received server request for topic '%s' but no handler registered. Sending error response.", tc.PageSessionID, msg.Header.Topic)
				errMsg := model.NewErrorMessage(&msg, map[string]string{"error": "no handler for topic: " + msg.Header.Topic})
				if errSend := tc.sendMessage(tc.ctx, errMsg); errSend != nil {
					tc.Logger.Error("TestClient %s: Failed to send 'no handler' error response: %v", tc.PageSessionID, errSend)
				}
			} else if !isResponseOrError && !dispatchedToSpecific {
				tc.Logger.Debug("TestClient %s: Received message for topic '%s' with no specific handler and not an RPC response.", tc.PageSessionID, msg.Header.Topic)
			}
		}
	}
}

// dispatchToHandler calls a registered handler and sends back its response/error if applicable.
func (tc *TestClient) dispatchToHandler(msg *model.Message, handler broker.MessageHandler) {
	// Create a new context for the handler call, derived from the client's main context.
	// This allows individual handler calls to potentially have their own timeouts or be cancelled.
	handlerCtx, cancelHandler := context.WithCancel(tc.ctx) // Or WithTimeout if handlers have max exec time
	defer cancelHandler()

	respPayload, err := handler(handlerCtx, msg, "") // Source client ID is not relevant for client-side handlers
	
	if msg.Header.Type == model.KindRequest && msg.Header.CorrelationID != "" { // If it was a server request
		if err != nil {
			tc.Logger.Error("TestClient %s: Handler for server request (Topic: %s, CorrID: %s) returned error: %v", tc.PageSessionID, msg.Header.Topic, msg.Header.CorrelationID, err)
			errMsg := model.NewErrorMessage(msg, map[string]string{"error": err.Error()})
			if errSend := tc.sendMessage(tc.ctx, errMsg); errSend != nil {
				tc.Logger.Error("TestClient %s: Failed to send handler error response for CorrID %s: %v", tc.PageSessionID, msg.Header.CorrelationID, errSend)
			}
		} else if respPayload != nil { // Handler returned a non-error response payload
			// The handler in TestClient context returns *model.Message directly
			// If it were JS, it would return the body, and we'd wrap it.
			// For this Go TestClient, assume handler returns full *model.Message
			var actualResponse *model.Message
			if respMsg, ok := respPayload.(*model.Message); ok {
				actualResponse = respMsg // Handler returned a full message
			} else { // Handler returned just a body
				actualResponse = model.NewResponse(msg, respPayload)
			}

			if errSend := tc.sendMessage(tc.ctx, actualResponse); errSend != nil {
				tc.Logger.Error("TestClient %s: Failed to send handler response for CorrID %s: %v", tc.PageSessionID, msg.Header.CorrelationID, errSend)
			} else {
				tc.Logger.Debug("TestClient %s: Sent handler response for CorrID %s, Topic %s", tc.PageSessionID, actualResponse.Header.CorrelationID, actualResponse.Header.Topic)
			}
		} else {
			// Handler returned nil payload and nil error for a request, meaning no explicit response.
			// This might be valid if the server request doesn't strictly require a reply (fire-and-forget request).
			tc.Logger.Debug("TestClient %s: Handler for server request (Topic: %s, CorrID: %s) returned nil response and nil error.", tc.PageSessionID, msg.Header.Topic, msg.Header.CorrelationID)
		}
	}
}


// RegisterHandler registers an RPC handler for a specific topic.
func (tc *TestClient) RegisterHandler(topic string, handler broker.MessageHandler) {
	tc.HandlersMutex.Lock()
	defer tc.HandlersMutex.Unlock()
	tc.Handlers[topic] = handler
	tc.Logger.Debug("TestClient %s: Registered handler for topic: %s", tc.PageSessionID, topic)
}

// SendRPC sends an RPC request to the server and waits for a response.
func (tc *TestClient) SendRPC(ctx context.Context, topic string, body interface{}, timeoutMs int64) (*model.Message, error) {
	if tc.BrokerClientID == "" { // Require registration (BrokerClientID set)
		return nil, errors.New("TestClient not registered, cannot send RPC")
	}
	req := model.NewRequest(topic, body, timeoutMs)
	tc.Logger.Debug("TestClient %s: Sending RPC: Topic=%s, CorrID=%s", tc.PageSessionID, topic, req.Header.CorrelationID)

	respChan := make(chan *model.Message, 1) // Buffered channel
	tc.ResponseMutex.Lock()
	tc.ResponseChannels[req.Header.CorrelationID] = respChan
	tc.ResponseMutex.Unlock()

	defer func() { // Cleanup
		tc.ResponseMutex.Lock()
		delete(tc.ResponseChannels, req.Header.CorrelationID)
		tc.ResponseMutex.Unlock()
		tc.Logger.Debug("TestClient %s: Cleaned up response channel for CorrID %s", tc.PageSessionID, req.Header.CorrelationID)
	}()

	if err := tc.sendMessage(ctx, req); err != nil {
		return nil, fmt.Errorf("TestClient %s: SendRPC failed to send message: %w", tc.PageSessionID, err)
	}

	// Use a combined timeout: min of context deadline and timeoutMs.
	effectiveTimeout := time.Duration(timeoutMs) * time.Millisecond
	if ctxDeadline, ok := ctx.Deadline(); ok {
		timeToCtxDeadline := time.Until(ctxDeadline)
		if timeToCtxDeadline < effectiveTimeout {
			effectiveTimeout = timeToCtxDeadline
		}
	}
	if effectiveTimeout <= 0 { // If context already expired or very short timeout
	    return nil, fmt.Errorf("TestClient %s: SendRPC effective timeout is zero or negative", tc.PageSessionID)
	}


	select {
	case <-ctx.Done(): // If the provided context for this RPC call is cancelled
		return nil, fmt.Errorf("TestClient %s: SendRPC context done for CorrID %s: %w", tc.PageSessionID, req.Header.CorrelationID, ctx.Err())
	case resp := <-respChan:
		tc.Logger.Debug("TestClient %s: SendRPC received response for CorrID %s", tc.PageSessionID, req.Header.CorrelationID)
		if resp.Header.Type == model.KindError {
			errMsg := "RPC error response from server"
			if errBody, ok := resp.Body.(map[string]interface{}); ok {
				if specificErr, ok := errBody["error"].(string); ok {
					errMsg = specificErr
				} else if specificMsg, ok := errBody["message"].(string); ok {
					errMsg = specificMsg
				}
			} else if errStr, ok := resp.Body.(string); ok {
				errMsg = errStr
			}
			return resp, fmt.Errorf(errMsg) // Return the error message along with the error itself
		}
		return resp, nil
	case <-time.After(effectiveTimeout + 200*time.Millisecond): // Add slight buffer to timeout
		return nil, fmt.Errorf("TestClient %s: SendRPC request timed out for CorrID %s after %v", tc.PageSessionID, req.Header.CorrelationID, effectiveTimeout)
	}
}

// Close closes the WebSocket connection and cleans up client resources.
func (tc *TestClient) Close() error {
	tc.Logger.Info("TestClient %s: Closing connection...", tc.PageSessionID)
	tc.cancel() // Signal all goroutines (like handleMessages) to stop by cancelling client's main context

	var err error
	if tc.Conn != nil {
		// Attempt a clean close of the WebSocket.
		// Use a short timeout for the close operation itself.
		closeCtx, cancelClose := context.WithTimeout(context.Background(), 3*time.Second)
		defer cancelClose()
		// nhooyr.io/websocket Close is context-aware for the write of the close frame.
		err = tc.Conn.Close(websocket.StatusNormalClosure, "client closing")
		if err != nil && !errors.Is(err, context.Canceled) && !errors.Is(err, context.DeadlineExceeded) {
			// Log error if it's not just context cancellation or timeout of the close operation itself.
			// It might also be an error indicating the connection was already gone.
			tc.Logger.Warn("TestClient %s: Error during WebSocket Close: %v", tc.PageSessionID, err)
		}
	}
	
	tc.wg.Wait() // Wait for handleMessages goroutine to fully exit
	tc.Logger.Info("TestClient %s: Connection closed and resources cleaned up.", tc.PageSessionID)
	return err // Return error from tc.Conn.Close() if any significant one occurred
}


// TestBasicConnectivity tests that a client can connect to the server and register.
func TestBasicConnectivity(t *testing.T) {
	server := NewTestServer(t)
	defer server.Close()
	<-server.Ready

	client := NewTestClient(t, server.Server.URL)
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	err := client.Connect(ctx)
	require.NoError(t, err, "Client failed to connect")

	select {
	case <-client.Connected:
		t.Logf("Client %s successfully connected and registered with BrokerClientID: %s", client.PageSessionID, client.BrokerClientID)
		assert.NotEmpty(t, client.BrokerClientID, "BrokerClientID should not be empty after connection")
	case <-time.After(8 * time.Second): 
		t.Fatal("Timed out waiting for client to be connected and registered")
	}
	require.NoError(t, client.Close())
}


// TestServerToClientRPC tests that the server can send an RPC request to a client.
func TestServerToClientRPC(t *testing.T) {
	server := NewTestServer(t)
	defer server.Close()
	<-server.Ready

	client := NewTestClient(t, server.Server.URL)
	ctx, cancel := context.WithTimeout(context.Background(), 15*time.Second)
	defer cancel()

	err := client.Connect(ctx)
	require.NoError(t, err)
	defer client.Close()

	select {
	case <-client.Connected:
		require.NotEmpty(t, client.BrokerClientID)
	case <-time.After(10 * time.Second):
		t.Fatal("Client did not connect and register in time")
	}

	handlerCalled := make(chan struct{})
	expectedParam := "server-to-client-param"
	client.RegisterHandler("client.action.echo", func(handlerCtx context.Context, msg *model.Message, _ string) (*model.Message, error) {
		t.Logf("Client handler for client.action.echo received: %+v", msg)
		params, ok := msg.Body.(map[string]interface{})
		require.True(t, ok, "Expected map[string]interface{} body")
		assert.Equal(t, expectedParam, params["param"])
		close(handlerCalled)
		return model.NewResponse(msg, map[string]string{"result": "echo-" + expectedParam}), nil
	})

	time.Sleep(100 * time.Millisecond) // Allow time for handler registration (though local, good practice)

	resp, err := server.SendRPCToClient(ctx, client.BrokerClientID, "client.action.echo", map[string]string{"param": expectedParam}, 5000)
	require.NoError(t, err, "Server.SendRPCToClient failed")
	require.NotNil(t, resp)

	select {
	case <-handlerCalled:
		// success
	case <-time.After(5 * time.Second):
		t.Fatal("Timed out waiting for client handler to be called")
	}

	assert.Equal(t, model.KindResponse, resp.Header.Type)
	respBody, ok := resp.Body.(map[string]interface{})
	require.True(t, ok)
	assert.Equal(t, "echo-"+expectedParam, respBody["result"])
}

// TestClientToServerRPC ensures a client can send an RPC to a server handler.
func TestClientToServerRPC(t *testing.T) {
	server := NewTestServer(t)
	defer server.Close()
	<-server.Ready

	serverHandlerCalled := make(chan struct{})
	expectedParam := "client-to-server-param"
	err := server.RegisterHandler("server.action.echo", func(handlerCtx context.Context, msg *model.Message, clientID string) (*model.Message, error) {
		t.Logf("Server handler for server.action.echo received from %s: %+v", clientID, msg)
		params, ok := msg.Body.(map[string]interface{})
		require.True(t, ok)
		assert.Equal(t, expectedParam, params["param"])
		close(serverHandlerCalled)
		return model.NewResponse(msg, map[string]string{"result": "server-echo-" + expectedParam}), nil
	})
	require.NoError(t, err)

	client := NewTestClient(t, server.Server.URL)
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	err = client.Connect(ctx)
	require.NoError(t, err)
	defer client.Close()
	
	select {
	case <-client.Connected: // Wait for registration
	    t.Log("Client connected and registered for TestClientToServerRPC")
	case <-time.After(8 * time.Second):
	    t.Fatal("Client did not connect/register in time for TestClientToServerRPC")
	}


	resp, err := client.SendRPC(ctx, "server.action.echo", map[string]string{"param": expectedParam}, 5000)
	require.NoError(t, err, "Client.SendRPC failed")
	require.NotNil(t, resp)

	select {
	case <-serverHandlerCalled:
		// success
	case <-time.After(5 * time.Second):
		t.Fatal("Timed out waiting for server handler to be called")
	}

	assert.Equal(t, model.KindResponse, resp.Header.Type)
	respBody, ok := resp.Body.(map[string]interface{})
	require.True(t, ok)
	assert.Equal(t, "server-echo-"+expectedParam, respBody["result"])
}


// TestBroadcastEventToManyClients: Server publishes an event, multiple clients should receive it.
// This test relies on the server explicitly sending to each client connection,
// as the ps.PubSubBroker.Publish method itself doesn't fan out to WebSocket clients
// based on topic subscriptions without additional logic.
func TestBroadcastEventToManyClients(t *testing.T) {
	server := NewTestServer(t)
	defer server.Close()
	<-server.Ready

	ctx, cancel := context.WithTimeout(context.Background(), 25*time.Second) // Increased timeout
	defer cancel()

	const clientCount = 3
	clients := make([]*TestClient, clientCount)
	clientBrokerIDs := make([]string, clientCount)
	
	var wgReceives sync.WaitGroup
	wgReceives.Add(clientCount)

	for i := 0; i < clientCount; i++ {
		c := NewTestClient(t, server.Server.URL)
		c.PageSessionID = fmt.Sprintf("broadcast-client-%d-%s", i, model.RandomID())
		err := c.Connect(ctx)
		require.NoError(t, err, "Client %d connect error", i)
		clients[i] = c
		defer c.Close() 

		select {
		case <-c.Connected:
			require.NotEmpty(t, c.BrokerClientID, "Client %d BrokerClientID not set", i)
			clientBrokerIDs[i] = c.BrokerClientID
			t.Logf("Client %d (%s) connected with BrokerID %s", i, c.PageSessionID, c.BrokerClientID)
		case <-time.After(10 * time.Second):
			t.Fatalf("Client %d did not connect and register", i)
		}
	}

	broadcastTopic := "event.system.alert"
	payload := map[string]string{"message": "System maintenance soon!"}
	receivedCounts := make([]int, clientCount) // No mutex needed if only incremented in its own goroutine from wgReceives
	
	for i := range clients {
		idx := i 
		clients[idx].RegisterHandler(broadcastTopic, func(handlerCtx context.Context, msg *model.Message, s string) (*model.Message, error) {
			t.Logf("Client %d (%s) received broadcast: %+v", idx, clients[idx].PageSessionID, msg.Body)
			assert.Equal(t, payload, msg.Body.(map[string]interface{}))
			receivedCounts[idx]++ // This is safe if each handler runs in its own goroutine context
			wgReceives.Done()
			return nil, nil
		})
	}

	// Server-side action that triggers the broadcast
	triggerBroadcastTopic := "admin.action.broadcastSystemAlert"
	err := server.RegisterHandler(triggerBroadcastTopic, func(handlerCtx context.Context, msg *model.Message, s string) (*model.Message, error) {
		t.Logf("Server handler for '%s' triggered. Broadcasting to %d known clients.", triggerBroadcastTopic, len(clientBrokerIDs))
		eventToSend := model.NewEvent(broadcastTopic, payload)

		psBroker, ok := server.Broker.(*ps.PubSubBroker)
		require.True(t, ok, "Broker is not a *ps.PubSubBroker")

		for j, clientID := range clientBrokerIDs {
			if clientID == "" { 
				t.Logf("Broadcast: Skipping empty clientID at index %d.", j)
				continue
			}
			conn, exists := psBroker.GetConnection(clientID)
			if !exists {
				t.Logf("Broadcast: Client %s not found by broker, skipping.", clientID)
				// This might happen if a client disconnected racefully.
				// For this test, we expect all to be there.
				// If a client legitimately disconnected, its wgReceives.Done() won't be called.
				// To handle this, we might need to adjust wgReceives.Add count if a client is known to be gone.
				// For simplicity now, assume they should all be there.
				continue 
			}
			if err := conn.WriteMessage(handlerCtx, eventToSend); err != nil {
				t.Logf("Broadcast: Error writing to client %s: %v", clientID, err)
			} else {
				t.Logf("Broadcast: Sent event to client %s", clientID)
			}
		}
		return model.NewResponse(msg, map[string]string{"status": "broadcast initiated"}), nil
	})
	require.NoError(t, err)

	// Trigger the broadcast
	_, err = server.Broker.Request(ctx, model.NewRequest(triggerBroadcastTopic, nil, 5000), 5000) // Increased timeout
	require.NoError(t, err, "Failed to trigger broadcast action")

	doneReceives := make(chan struct{})
	go func() {
		wgReceives.Wait()
		close(doneReceives)
	}()
	
	select {
	case <-doneReceives:
		t.Log("All clients signaled receipt.")
	case <-time.After(12 * time.Second): // Timeout for all clients to receive
		t.Fatal("Timed out waiting for all clients to receive broadcast")
	}

	for i := 0; i < clientCount; i++ {
		assert.Equal(t, 1, receivedCounts[i], "Client %d: expected 1 message, got %d", i, receivedCounts[i])
	}
}


// TestClientDisconnectTriggersDeregistration: Verifies server handles client disconnect.
func TestClientDisconnectTriggersDeregistration(t *testing.T) {
	server := NewTestServer(t)
	defer server.Close()
	<-server.Ready

	deregistrationReceived := make(chan string, 1) // Stores BrokerClientID of deregistered client
	err := server.RegisterHandler(broker.TopicClientDeregistered, func(ctx context.Context, msg *model.Message, _ string) (*model.Message, error) {
		t.Logf("Server received deregistration event: %+v", msg.Body)
		bodyMap, ok := msg.Body.(map[string]interface{}) // From JSON unmarshal
		require.True(t, ok)
		clientID, ok := bodyMap["brokerClientID"].(string)
		require.True(t, ok)
		deregistrationReceived <- clientID
		return nil, nil
	})
	require.NoError(t, err)

	client := NewTestClient(t, server.Server.URL)
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	err = client.Connect(ctx)
	require.NoError(t, err)
	select {
	case <-client.Connected:
		require.NotEmpty(t, client.BrokerClientID)
	case <-time.After(8 * time.Second):
		t.Fatal("Client registration timeout")
	}
	originalClientID := client.BrokerClientID

	// Close client connection
	t.Logf("TestClient %s (BrokerID: %s) is closing its connection.", client.PageSessionID, originalClientID)
	err = client.Close() 
	require.NoError(t, err, "Error closing client")

	select {
	case deregisteredID := <-deregistrationReceived:
		assert.Equal(t, originalClientID, deregisteredID, "Deregistered clientID mismatch")
	case <-time.After(8 * time.Second): // Increased timeout for server processing
		t.Fatal("Timed out waiting for server deregistration event")
	}

	// Verify broker no longer knows the client
	_, err = server.SendRPCToClient(ctx, originalClientID, "any.topic", nil, 1000)
	assert.ErrorIs(t, err, broker.ErrClientNotFound, "Expected ErrClientNotFound for RPC to disconnected client")
}

// TestOversizeMessageRejected (as per test plan)
func TestOversizeMessageRejected(t *testing.T) {
	maxSize := int64(1024 * 10) // 10KB for test, default is 1MB
	handlerOpts := server.DefaultHandlerOptions()
	handlerOpts.MaxMessageSize = maxSize
	
	server := NewTestServer(t, handlerOpts) // Pass custom handler options
	defer server.Close()
	<-server.Ready

	client := NewTestClient(t, server.Server.URL)
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	err := client.Connect(ctx)
	require.NoError(t, err, "Client failed to connect")
	<-client.Connected // Wait for registration

	// Build a payload larger than MaxMessageSize
	// MaxMessageSize is for the WebSocket frame, JSON adds overhead.
	// Let's make the string itself clearly larger.
	bigBody := strings.Repeat("X", int(maxSize*2)) 
	oversizedEvent := model.NewEvent("test.oversize", bigBody)
	
	tc := client
	tc.Logger.Info("TestClient %s: Attempting to send oversized message (body len: %d, limit: %d)", tc.PageSessionID, len(bigBody), maxSize)

	// Sending an oversized message from client to server.
	// The server's nhooyr.io/websocket library should reject it and close the connection.
	sendErr := tc.sendMessage(ctx, oversizedEvent)

	if sendErr == nil {
		// If sendErr is nil, the message might have been accepted by the client's OS buffer
		// but rejected by the server upon receipt. We then expect the client's connection to be closed.
		tc.Logger.Info("TestClient %s: Oversized message sent (or buffered by OS), waiting for server to close connection.", tc.PageSessionID)
		select {
		case <-tc.Closed: // handleMessages loop exited, likely due to server closing conn
			tc.Logger.Info("TestClient %s: Connection closed by server as expected after sending oversized message.", tc.PageSessionID)
			// This is the success path if the server correctly closes.
		case <-time.After(5 * time.Second):
			t.Fatal("TestClient %s: Server did not close connection after oversized message was sent (or send failed silently).", tc.PageSessionID)
		}
	} else {
		// If sendErr is not nil, the client-side send itself might have failed,
		// possibly due to immediate connection closure or other WebSocket errors.
		tc.Logger.Warn("TestClient %s: Sending oversized message failed client-side: %v. This might also indicate server rejection.", tc.PageSessionID, sendErr)
		// This can also be a pass condition if the error indicates the connection was closed due to the large message.
		// For nhooyr, the server closes with StatusMessageTooBig. The client read loop will see this.
		// The client's `sendMessage` might not error directly if the server closes *after* write starts.
		// The most reliable check is `<-tc.Closed`.
		select {
		case <-tc.Closed: 
			tc.Logger.Info("TestClient %s: Connection closed, consistent with server rejecting oversized message.", tc.PageSessionID)
		case <-time.After(2 * time.Second): // Shorter wait if send failed
			t.Logf("TestClient %s: Send failed, but connection didn't close immediately from client perspective. Error: %v", tc.PageSessionID, sendErr)
			// This might still be a pass if the server did reject it, but client's error handling is more complex.
			// The core test is that the server enforces the limit.
		}
	}
	// The key is that the server's `conn.Read` in `server.Handler` should get an error
	// (like `websocket.StatusMessageTooBig`) which then closes the connection.
	// The client will then observe this closure.
}

// TestUnknownActionReturnsError (Server-to-Client RPC)
func TestUnknownActionReturnsError(t *testing.T) {
	server := NewTestServer(t)
	defer server.Close()
	<-server.Ready

	client := NewTestClient(t, server.Server.URL)
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	err := client.Connect(ctx)
	require.NoError(t, err)
	<-client.Connected
	defer client.Close()

	unknownTopic := "client.action.nonexistent"
	reqPayload := map[string]string{"data": "test"}
	
	// Server sends RPC to client for an action client is NOT subscribed to.
	respMsg, err := server.SendRPCToClient(ctx, client.BrokerClientID, unknownTopic, reqPayload, 2000)
	
	// The TestClient's handleMessages is designed to send an error back if no handler is found for a request.
	require.NoError(t, err, "SendRPCToClient itself should succeed, error is in client response")
	require.NotNil(t, respMsg, "Response message should not be nil")
	
	assert.Equal(t, model.KindError, respMsg.Header.Type, "Expected error response type")
	errBody, ok := respMsg.Body.(map[string]interface{})
	require.True(t, ok, "Error body should be a map")
	assert.Contains(t, errBody["error"], "no handler for topic: "+unknownTopic, "Error message mismatch")
}


// TestTTLExpiresServerSide (Server-to-Handler RPC)
func TestTTLExpiresServerSide(t *testing.T) {
	server := NewTestServer(t)
	defer server.Close()
	<-server.Ready

	timeoutTopic := "rpc.server.ttl_expire"
	// No handler subscribed to this topic, so any request to it will eventually time out
	// based on the request's TTL or the broker's default.

	reqMsg := model.NewRequest(timeoutTopic, "data", 100) // 100ms TTL
	
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()

	_, err := server.Broker.Request(ctx, reqMsg, 100) // Pass TTL from message
	
	require.Error(t, err, "Expected request to time out")
	assert.ErrorIs(t, err, broker.ErrRequestTimeout, "Expected ErrRequestTimeout")
}
```

I've added the new tests `TestOversizeMessageRejected`, `TestUnknownActionReturnsError`, and `TestTTLExpiresServerSide` to `integration_test.go`. The other new tests from the plan (`TestDuplicatePageSessionReconnect`, `TestConcurrentLargeFanout`, `TestWriteFailureTriggersDeregistration`, `TestPingIntervalKeepsConnectionAlive`) would require more specific setups or modifications to `TestClient` or `MockConnectionWriter` to simulate those conditions precisely.

For example:
*   `TestDuplicatePageSessionReconnect`: Would need two `TestClient` instances trying to register with the same `PageSessionID` and a `session.Manager` involved.
*   `TestWriteFailureTriggersDeregistration`: `MockConnectionWriter.WriteMessageFn` could be set to return `broker.ErrConnectionWrite` and then verify `DeregisterConnection` is called.
*   `TestPingIntervalKeepsConnectionAlive`: This is more about application-level logic built on top of WebSocketMQ; the library itself (via `nhooyr.io/websocket`) handles underlying WebSocket pings.

I'll proceed with `rpc_test.go` and then `js_client_test.go`.

**File: pkg/broker/ps/rpc_test.go**
```go
// pkg/broker/ps/rpc_test.go
package ps_test // Use the same package as integration_test to reuse TestServer/TestClient

import (
	"context"
	// "errors" // Not directly used in this version of the test
	// "sync"   // Not directly used in this version of the test
	"testing"
	"time"

	"github.com/lightforgemedia/go-websocketmq/pkg/broker"
	"github.com/lightforgemedia/go-websocketmq/pkg/model"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// TestClientToServerRPC_Detailed tests client-to-server RPC with more detailed logging and checks.
// This test focuses on the broker's role in facilitating this.
func TestClientToServerRPC_Detailed(t *testing.T) {
	server := NewTestServer(t) // Uses integration_test.go's TestServer
	defer server.Close()
	<-server.Ready
	t.Logf("Test server for TestClientToServerRPC_Detailed running at: %s", server.Server.URL)

	handlerCalled := make(chan *model.Message, 1)
	expectedParam := "rpc-detailed-param"
	serverEchoTopic := "server.echo.detailed"

	// Register the server-side handler
	err := server.Broker.Subscribe(context.Background(), serverEchoTopic, func(ctx context.Context, msg *model.Message, clientID string) (*model.Message, error) {
		t.Logf("Server handler for '%s': Received from BrokerClientID %s, Body: %+v", serverEchoTopic, clientID, msg.Body)
		handlerCalled <- msg
		
		params, ok := msg.Body.(map[string]interface{})
		require.True(t, ok, "Server handler: Expected body to be map[string]interface{}")
		assert.Equal(t, expectedParam, params["param"], "Server handler: 'param' mismatch")
		
		return model.NewResponse(msg, map[string]string{"result": "echo-" + expectedParam, "handler_id": clientID}), nil
	})
	require.NoError(t, err, "Failed to subscribe server handler")

	// Create and connect a TestClient (Go WebSocket client)
	client := NewTestClient(t, server.Server.URL)
	ctx, cancel := context.WithTimeout(context.Background(), 15*time.Second) // Increased timeout
	defer cancel()

	err = client.Connect(ctx)
	require.NoError(t, err, "TestClient failed to connect")
	defer client.Close()

	select {
	case <-client.Connected:
		t.Logf("TestClient %s connected with BrokerClientID %s", client.PageSessionID, client.BrokerClientID)
		require.NotEmpty(t, client.BrokerClientID, "TestClient BrokerClientID is empty after connect")
	case <-time.After(10 * time.Second): // Increased timeout
		t.Fatal("TestClient timed out waiting for connection and registration")
	}
	
	// Client sends RPC request to the server handler
	requestPayload := map[string]string{"param": expectedParam}
	t.Logf("TestClient %s: Sending RPC request to topic '%s' with payload: %+v", client.PageSessionID, serverEchoTopic, requestPayload)
	
	respMsg, err := client.SendRPC(ctx, serverEchoTopic, requestPayload, 5000) // 5s timeout for RPC
	require.NoError(t, err, "TestClient.SendRPC failed")
	require.NotNil(t, respMsg, "Received nil response message from SendRPC")

	// Verify server handler was called
	var receivedReqByHandler *model.Message
	select {
	case receivedReqByHandler = <-handlerCalled:
		t.Logf("Server handler for '%s' was called with message ID %s", serverEchoTopic, receivedReqByHandler.Header.MessageID)
		assert.Equal(t, client.BrokerClientID, receivedReqByHandler.Header.SourceBrokerClientID, "SourceBrokerClientID in handler mismatch")
	case <-time.After(5 * time.Second):
		t.Fatal("Timed out waiting for server handler to be called")
	}

	// Verify client received the correct response
	assert.Equal(t, model.KindResponse, respMsg.Header.Type, "Response message type mismatch")
	assert.Equal(t, receivedReqByHandler.Header.CorrelationID, respMsg.Header.CorrelationID, "CorrelationID mismatch in response")
	
	respBody, ok := respMsg.Body.(map[string]interface{})
	require.True(t, ok, "Response body is not map[string]interface{}")
	assert.Equal(t, "echo-"+expectedParam, respBody["result"], "Response body 'result' mismatch")
	assert.Equal(t, client.BrokerClientID, respBody["handler_id"], "Response body 'handler_id' (BrokerClientID from handler) mismatch")

	t.Logf("TestClient %s: Successfully received RPC response: %+v", client.PageSessionID, respMsg.Body)
}

// TestRPCErrorsAndBrokerInteraction focuses on error conditions in RPC and broker state.
func TestRPCErrorsAndBrokerInteraction(t *testing.T) {
	server := NewTestServer(t)
	defer server.Close()
	<-server.Ready

	ctx, cancel := context.WithTimeout(context.Background(), 20*time.Second)
	defer cancel()

	// Scenario 1: Client RPC to a server handler that returns an error
	t.Run("ClientToServer_HandlerError", func(t *testing.T) {
		errorTopic := "server.handler.erroring"
		expectedErrorMessage := "intentional error from server handler"
		err := server.Broker.Subscribe(context.Background(), errorTopic, func(ctx context.Context, msg *model.Message, clientID string) (*model.Message, error) {
			t.Logf("Server handler for '%s' (expecting error): Received from %s", errorTopic, clientID)
			// No need to return a model.ErrorMessage here, just return an error.
			// The broker's ps.PubSubBroker.dispatchToTopicHandlers should convert this to a model.ErrorMessage.
			return nil, errors.New(expectedErrorMessage)
		})
		require.NoError(t, err)

		client := NewTestClient(t, server.Server.URL)
		err = client.Connect(ctx)
		require.NoError(t, err); <-client.Connected; defer client.Close()

		respMsg, rpcErr := client.SendRPC(ctx, errorTopic, map[string]string{"data": "trigger"}, 3000)
		
		require.Error(t, rpcErr, "Expected SendRPC to return an error because server handler errored")
		// The error from SendRPC should contain the server's error message.
		// TestClient.SendRPC wraps the error message from the KindError response.
		assert.Contains(t, rpcErr.Error(), expectedErrorMessage, "RPC error message mismatch")

		// respMsg might be nil or a KindError message depending on TestClient.SendRPC implementation for errors.
		// If SendRPC returns the error message itself in `rpcErr`, `respMsg` might be nil.
		// If SendRPC resolves with the KindError message, then `respMsg` would be non-nil.
		// Current TestClient.SendRPC returns (resp, fmt.Errorf(errMsg)) for KindError.
		require.NotNil(t, respMsg, "respMsg should be the KindError message")
		require.Equal(t, model.KindError, respMsg.Header.Type)
		errBody, ok := respMsg.Body.(map[string]interface{})
		require.True(t, ok)
		assert.Contains(t, errBody["error"], expectedErrorMessage)
	})

	// Scenario 2: Server RPC to a client that is not found
	t.Run("ServerToClient_ClientNotFound", func(t *testing.T) {
		nonExistentClientID := "client-does-not-exist-" + model.RandomID()
		reqMsg := model.NewRequest("client.action", "payload", 1000)
		
		_, err := server.Broker.RequestToClient(ctx, nonExistentClientID, reqMsg, 1000)
		require.Error(t, err, "Expected error when RPCing to non-existent client")
		assert.ErrorIs(t, err, broker.ErrClientNotFound, "Expected ErrClientNotFound")
	})

	// Scenario 3: Server RPC to client, but client's ConnectionWriter fails
	t.Run("ServerToClient_ConnectionWriteError", func(t *testing.T) {
		client := NewTestClient(t, server.Server.URL)
		err := client.Connect(ctx)
		require.NoError(t, err); <-client.Connected // Wait for actual connection

		// Get the actual ConnectionWriter from the broker to simulate its failure
		psb := server.Broker.(*ps.PubSubBroker)
		connWriter, found := psb.GetConnection(client.BrokerClientID)
		require.True(t, found, "Could not get ConnectionWriter for connected client")
		
		// Replace WriteMessage with one that errors
		// This requires connWriter to be the MockConnectionWriter or an interface allowing this.
		// For this test, we'll simulate the client disconnecting abruptly, causing WriteMessage to fail.
		originalConn := client.Conn // Keep original to close test client properly
		
		// Simulate client connection dropping by closing it from client side *before* server tries to write
		// This is a bit racy, but aims to make connWriter.WriteMessage fail.
		client.Conn.Close(websocket.StatusAbnormalClosure, "simulated drop for write error test")
		// Wait a moment for the close to propagate or be noticed by server's read loop (if any test relied on that)
		time.Sleep(100 * time.Millisecond) 


		reqMsg := model.NewRequest("client.action.writefail", "payload", 2000)
		_, rpcErr := server.Broker.RequestToClient(ctx, client.BrokerClientID, reqMsg, 2000)
		
		require.Error(t, rpcErr, "Expected error from RequestToClient due to write failure")
		// The error could be ErrConnectionWrite or ErrClientNotFound if deregistration happened quickly.
		assert.True(t, errors.Is(rpcErr, broker.ErrConnectionWrite) || errors.Is(rpcErr, broker.ErrClientNotFound) || errors.Is(rpcErr, context.DeadlineExceeded),
			"Expected ErrConnectionWrite, ErrClientNotFound or context.DeadlineExceeded, got: %v", rpcErr)

		// Clean up the TestClient properly (even though its connection was manually closed)
		client.Conn = originalConn // Restore for Close() method if it expects it
		client.Close() // Call TestClient's Close to cancel context and wait for goroutines
	})
}
```

Finally, `pkg/broker/ps/js_client_test.go`. This is the most complex to update fully without running it, as it involves browser interaction. I'll update it to use `testify` and align with the refined JS client and server logic. The success of these tests heavily depends on the correctness of `assets/dist/websocketmq.js` and the test HTML files.

**File: pkg/broker/ps/js_client_test.go**
```go
// pkg/broker/ps/js_client_test.go
package ps_test // Use the same package as integration_test to reuse TestServer/TestClient

import (
	"context"
	"encoding/json"
	"fmt"
	"net/http"
	"net/http/httptest" // Use httptest for serving test files
	"path/filepath"
	"runtime"
	"strings"
	"sync"
	"testing"
	"time"

	"github.com/go-rod/rod"
	"github.com/go-rod/rod/lib/launcher"
	"github.com/go-rod/rod/lib/proto"
	"github.com/lightforgemedia/go-websocketmq/pkg/broker"
	"github.com/lightforgemedia/go-websocketmq/pkg/model"
	"github.com/lightforgemedia/go-websocketmq/pkg/server" // For server.DefaultHandlerOptions
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

var (
	jsTestdataRoot string
	jsTestOnce     sync.Once
)

func setupJSTestdataRoot() {
	_, filename, _, _ := runtime.Caller(0)
	// Assumes js_client_test.go is in pkg/broker/ps/
	// testdata is ../../../testdata/
	// assets are ../../../assets/
	jsTestdataRoot = filepath.Join(filepath.Dir(filename), "..", "..", "..") // Project root
}

func getJSTestdataRoot() string {
	jsTestOnce.Do(setupJSTestdataRoot)
	return jsTestdataRoot
}

// serveTestFiles serves files from the project's testdata and assets directories.
func serveTestFiles(t *testing.T, w http.ResponseWriter, r *http.Request) {
	projectRoot := getJSTestdataRoot()
	path := r.URL.Path
	t.Logf("File server request for: %s", path)

	var servePath string
	if strings.HasPrefix(path, "/wsmq/") { // For websocketmq.js from assets
		// This matches how cmd/rpcserver/main.go serves it via assets.ScriptHandler
		// We need to serve assets/dist/websocketmq.js when /wsmq/websocketmq.js is requested.
		assetName := strings.TrimPrefix(path, "/wsmq/")
		servePath = filepath.Join(projectRoot, "assets", "dist", assetName)
	} else if strings.HasSuffix(path, ".js") && !strings.Contains(path, "testdata") {
		// General JS files might be from static mocks
		servePath = filepath.Join(projectRoot, "cmd", "rpcserver", "static", strings.TrimPrefix(path, "/"))
	} else { // HTML, CSS from testdata or cmd/rpcserver/static
		// Prioritize testdata for test-specific HTML like simple_test.html
		testdataFilePath := filepath.Join(projectRoot, "testdata", strings.TrimPrefix(path, "/"))
		if _, err :=體.Stat(testdataFilePath); err == nil {
			servePath = testdataFilePath
		} else {
			// Fallback to cmd/rpcserver/static for general static assets like style.css
			servePath = filepath.Join(projectRoot, "cmd", "rpcserver", "static", strings.TrimPrefix(path, "/"))
		}
	}
	
	t.Logf("Attempting to serve file: %s", servePath)
	http.ServeFile(w, r, servePath)
}


// TestJSClient_SimpleConnectivity uses simple_test.html and the refined websocketmq.js
func TestJSClient_SimpleConnectivity(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping browser test in short mode.")
	}

	handlerOpts := server.DefaultHandlerOptions() // Use defaults that JS client expects
	server := NewTestServer(t, handlerOpts) 
	defer server.Close()
	<-server.Ready
	t.Logf("Test server for JS SimpleConnectivity running at: %s", server.Server.URL)

	// This channel will receive the BrokerClientID when the server processes the registration event
	// published by server.Handler upon client's _client.register message.
	clientRegisteredOnServer := make(chan string, 1)
	err := server.Broker.Subscribe(context.Background(), broker.TopicClientRegistered, func(ctx context.Context, msg *model.Message, _ string) (*model.Message, error) {
		t.Logf("Server: Event on %s received: %+v", broker.TopicClientRegistered, msg.Body)
		bodyMap, ok := msg.Body.(map[string]interface{}) // ps.PubSubBroker publishes map[string]string, json unmarshals to this
		if !ok {
			t.Errorf("Server: Bad body type for %s: %T", broker.TopicClientRegistered, msg.Body)
			return nil, fmt.Errorf("bad body type for %s", broker.TopicClientRegistered)
		}
		clientID, ok := bodyMap["brokerClientID"].(string)
		if !ok {
			t.Errorf("Server: Missing brokerClientID in %s event: %+v", broker.TopicClientRegistered, bodyMap)
			return nil, fmt.Errorf("missing brokerClientID in %s event", broker.TopicClientRegistered)
		}
		clientRegisteredOnServer <- clientID
		return nil, nil
	})
	require.NoError(t, err, "Failed to subscribe to TopicClientRegistered on server broker")

	httpTestServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		serveTestFiles(t, w, r)
	}))
	defer httpTestServer.Close()
	t.Logf("File server for JS test assets running at: %s", httpTestServer.URL)

	l := launcher.New().Headless(true).MustLaunch()
	browser := rod.New().ControlURL(l).MustConnect()
	defer browser.MustClose()

	wsURLForJS := strings.Replace(server.Server.URL, "http://", "ws://", 1) + "/ws"
	// simple_test.html expects websocketmq.js to be at /wsmq/websocketmq.js
	// but our file server serves it from /assets/dist/websocketmq.js if requested as /websocketmq.js
	// For this test, simple_test.html is modified to load from `/wsmq/websocketmq.js`
	// The file server needs to handle this path correctly.
	pageURL := fmt.Sprintf("%s/simple_test.html?ws=%s", httpTestServer.URL, wsURLForJS)
	t.Logf("Navigating browser to: %s", pageURL)

	page := browser.MustPage(pageURL).MustWaitLoad()
	defer page.MustClose()

	var receivedBrokerIDFromServer string
	select {
	case receivedBrokerIDFromServer = <-clientRegisteredOnServer:
		t.Logf("Server confirmed JS client registration via broker event, assigned BrokerClientID: %s", receivedBrokerIDFromServer)
		require.NotEmpty(t, receivedBrokerIDFromServer)
	case <-time.After(20 * time.Second): // Increased timeout for browser init + registration
		logBrowserConsole(t, page)
		t.Fatalf("Timeout waiting for JS client registration confirmation from server (via %s event)", broker.TopicClientRegistered)
	}

	// Verify status on the page (simple_test.html should update #status and #client-id)
	statusEl := page.MustElement("#status")
	require.EventuallyWithT(t, func(c *assert.CollectT) {
		s, err := statusEl.Text()
		assert.NoError(c, err)
		assert.Equal(c, "Connected", s, "JS client status on page did not become 'Connected'")
	}, 15*time.Second, 300*time.Millisecond, "JS client on-page status check timed out")

	clientIDOnPageEl := page.MustElement("#client-id")
	require.EventuallyWithT(t, func(c *assert.CollectT) {
		idText, err := clientIDOnPageEl.Text()
		assert.NoError(c, err)
		assert.Equal(c, receivedBrokerIDFromServer, idText, "BrokerClientID on page should match server-assigned ID from ACK")
	}, 15*time.Second, 300*time.Millisecond, "JS client on-page BrokerClientID check timed out")
	
	t.Log("JS Client simple connectivity and registration ACK verified.")

	t.Cleanup(func() {
		if t.Failed() {
			logBrowserConsole(t, page)
			path := filepath.Join(getJSTestdataRoot(), "testdata", "simple_connectivity_failure.png")
			_ = page.MustScreenshot(path)
			t.Logf("Screenshot saved to %s", path)
		}
	})
}

// TestJSClient_FullRPCSuite uses cmd/rpcserver/static/index.html and assets/dist/websocketmq.js
// This test simulates the full application flow.
func TestJSClient_FullRPCSuite(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping full browser RPC suite in short mode.")
	}

	// Setup server similar to cmd/rpcserver/main.go
	logger := testutil.NewTestLogger(t)
	brokerOpts := broker.DefaultOptions()
	brokerInstance := ps.New(logger, brokerOpts)
	
	sessionManager := NewMockSessionManager(logger) // Using a mock session manager for this test
	
	wsHandlerOpts := server.DefaultHandlerOptions()
	wsHandlerOpts.ClientRegisterTopic = "_client.register"
	wsHandlerOpts.ClientRegisteredAckTopic = broker.TopicClientRegistered // JS client listens on this for ACK
	wsHandler := server.NewHandler(brokerInstance, logger, wsHandlerOpts)
	
	// Mock API handler setup (not strictly needed if we trigger RPCs directly, but good for context)
	// For this test, we'll mostly interact via server.Broker.RequestToClient or listen to client-sent RPCs.

	// Subscribe to server-side topics the JS client will call
	err := brokerInstance.Subscribe(context.Background(), "server.ping", func(ctx context.Context, msg *model.Message, sourceBrokerID string) (*model.Message, error) {
		t.Logf("Server: 'server.ping' handler received from BrokerClientID %s, Body: %+v", sourceBrokerID, msg.Body)
		return model.NewResponse(msg, map[string]interface{}{"reply": "pong from Go server.ping", "client_payload": msg.Body}), nil
	})
	require.NoError(t, err)

	// HTTP server setup
	mux := http.NewServeMux()
	mux.Handle("/ws", wsHandler)
	// Serve static files (index.html, browser_automation_mock.js, style.css, and websocketmq.js)
	mux.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
		serveTestFiles(t, w, r) // Use the common file server
	})
	
	testHTTPServer := httptest.NewServer(mux)
	defer testHTTPServer.Close()
	t.Logf("Test server for Full RPC Suite running at: %s", testHTTPServer.URL)
	
	// Setup Rod browser
	l := launcher.New().Headless(true).Delete("disable-gpu").MustLaunch() // Headless for CI
	browser := rod.New().ControlURL(l).MustConnect()
	defer browser.MustClose()

	wsURLForJS := strings.Replace(testHTTPServer.URL, "http://", "ws://", 1) + "/ws"
	// index.html is served from cmd/rpcserver/static by our file server
	// It loads /wsmq/websocketmq.js and /browser_automation_mock.js
	pageURL := fmt.Sprintf("%s/index.html?ws=%s", testHTTPServer.URL, wsURLForJS) // index.html is in cmd/rpcserver/static
	t.Logf("Navigating browser to: %s", pageURL)

	page := browser.MustPage(pageURL).MustWaitLoad()
	defer page.MustClose()

	// --- Wait for client to connect and register ---
	var jsPageSessionID, jsBrokerClientID string
	require.EventuallyWithT(t, func(c *assert.CollectT) {
		pageID, err := page.MustElement("#page-session-id").Text()
		assert.NoError(c, err)
		assert.NotEmpty(c, pageID, "PageSessionID not displayed on page")
		jsPageSessionID = pageID

		brokerID, err := page.MustElement("#broker-client-id").Text()
		assert.NoError(c, err)
		assert.NotEmpty(c, brokerID, "BrokerClientID not displayed on page")
		assert.NotEqual(c, "N/A", brokerID, "BrokerClientID is N/A, registration ACK not received/processed by JS")
		jsBrokerClientID = brokerID
		
		// Update mock session manager with this mapping
		sessionManager.Store(jsPageSessionID, jsBrokerClientID)

	}, 25*time.Second, 500*time.Millisecond, "JS client did not display PageSessionID and BrokerClientID")
	t.Logf("JS Client on index.html connected: PageSessionID=%s, BrokerClientID=%s", jsPageSessionID, jsBrokerClientID)

	// --- Test Scenarios ---

	// 1. Client-Initiated RPC to Server (server.ping)
	t.Run("JSClientToServer_Ping", func(t *testing.T) {
		page.MustElement("#client-ping-server").MustClick()
		pingResponseEl := page.MustElement("#client-ping-response")
		require.EventuallyWithT(t, func(c *assert.CollectT) {
			respText, err := pingResponseEl.Text()
			assert.NoError(c, err)
			assert.Contains(c, respText, "pong from server handler", "Ping response mismatch")
			assert.Contains(c, respText, "ping from client", "Ping response did not echo client data")
		}, 10*time.Second, 200*time.Millisecond, "Client ping response not updated in UI")
		t.Log("JSClientToServer_Ping: Passed")
	})

	// 2. Server-Initiated RPC to JS Client (e.g., browser.click, simulated via API call path)
	//    For this, we'll directly use brokerInstance.RequestToClient, simulating what api.Handler would do.
	t.Run("ServerToJSClient_BrowserClick", func(t *testing.T) {
		actionTopic := "browser.click"
		actionParams := map[string]interface{}{"selector": "#test-button-1"}
		
		rpcCtx, rpcCancel := context.WithTimeout(context.Background(), 10*time.Second)
		defer rpcCancel()

		respMsg, err := brokerInstance.RequestToClient(rpcCtx, jsBrokerClientID, model.NewRequest(actionTopic, actionParams, 5000), 5000)
		require.NoError(t, err, "RequestToClient for browser.click failed")
		require.NotNil(t, respMsg, "Response from browser.click was nil")
		assert.Equal(t, model.KindResponse, respMsg.Header.Type)
		
		respData, ok := respMsg.Body.(map[string]interface{})
		require.True(t, ok, "browser.click response body not a map")
		assert.True(t, respData["success"].(bool), "browser.click mock did not return success:true")
		assert.Contains(t, respData["message"].(string), "#test-button-1", "browser.click response message mismatch")

		// Check UI log on page for this action
		actionLogEl := page.MustElement("#action-log")
		require.EventuallyWithT(t, func(c *assert.CollectT) {
			logHTML, err := actionLogEl.HTML()
			assert.NoError(c, err)
			assert.Contains(c, logHTML, "Received RPC: browser.click", "browser.click not logged in action log")
			assert.Contains(c, logHTML, "#test-button-1", "selector not logged for browser.click")
		}, 5*time.Second, 200*time.Millisecond, "Action log for browser.click not updated")
		t.Log("ServerToJSClient_BrowserClick: Passed")
	})

	// 3. Server-Initiated RPC to JS Client - Handler throws error
	t.Run("ServerToJSClient_HandlerError", func(t *testing.T) {
		actionTopic := "browser.input" // Assume browser.input mock can be made to fail
		// To make it fail, we'd need to modify browser_automation_mock.js or send params that cause it to error.
		// For simplicity, let's assume a hypothetical "browser.forceError" action.
		// We'll register a temporary handler in JS via Evaluate to simulate this.
		page.MustEvaluate(rod.Eval(`
			client.subscribe("browser.forceError", async (params) => {
				clientLogger.info("JS handler for browser.forceError called with:", params);
				throw new Error("Simulated JS handler error for browser.forceError");
			});
			clientLogger.info("Temporary JS handler for browser.forceError registered.");
		`))
		time.Sleep(200*time.Millisecond) // Give time for eval to register

		rpcCtx, rpcCancel := context.WithTimeout(context.Background(), 10*time.Second)
		defer rpcCancel()
		
		respMsg, err := brokerInstance.RequestToClient(rpcCtx, jsBrokerClientID, model.NewRequest("browser.forceError", nil, 5000), 5000)
		require.NoError(t, err, "RequestToClient for browser.forceError should not error itself")
		require.NotNil(t, respMsg, "Response from browser.forceError was nil")
		assert.Equal(t, model.KindError, respMsg.Header.Type, "Expected KindError response")
		
		errData, ok := respMsg.Body.(map[string]interface{})
		require.True(t, ok, "Error response body not a map")
		assert.Contains(t, errData["error"].(string), "Simulated JS handler error", "Error message mismatch")
		t.Log("ServerToJSClient_HandlerError: Passed")
	})
	
	// 4. Server-Initiated RPC to JS Client - Timeout (JS handler doesn't respond)
	t.Run("ServerToJSClient_Timeout", func(t *testing.T) {
		page.MustEvaluate(rod.Eval(`
			client.subscribe("browser.forceTimeout", async (params) => {
				clientLogger.info("JS handler for browser.forceTimeout called. Will not respond.");
				// No return, no throw, just hang.
				return new Promise(() => {}); // Promise that never resolves
			});
			clientLogger.info("Temporary JS handler for browser.forceTimeout registered.");
		`))
		time.Sleep(200*time.Millisecond)

		rpcCtx, rpcCancel := context.WithTimeout(context.Background(), 3*time.Second) // Overall test timeout
		defer rpcCancel()
		
		// RPC call with a shorter timeout for the broker.RequestToClient itself
		_, err := brokerInstance.RequestToClient(rpcCtx, jsBrokerClientID, model.NewRequest("browser.forceTimeout", nil, 1500), 1500) // 1.5s timeout
		require.Error(t, err, "Expected RequestToClient to timeout")
		assert.True(t, errors.Is(err, broker.ErrRequestTimeout) || errors.Is(err, context.DeadlineExceeded), "Expected ErrRequestTimeout or context.DeadlineExceeded, got: %v", err)
		t.Log("ServerToJSClient_Timeout: Passed")
	})


	t.Log("JS Client Full RPC Suite appears to have passed relevant scenarios.")
	t.Cleanup(func() {
		if t.Failed() {
			logBrowserConsole(t, page)
			path := filepath.Join(getJSTestdataRoot(), "testdata", "js_full_rpc_suite_failure.png")
			_ = page.MustScreenshot(path)
			t.Logf("Screenshot saved to %s", path)
		}
		// Clean up broker and session manager if they were specifically created for this test block
		// For now, server.Close() handles brokerInstance.Close()
	})
}

// Helper to log browser console output for debugging failed tests
func logBrowserConsole(t *testing.T, page *rod.Page) {
	t.Helper()
	t.Logf("--- Browser Console Logs for URL: %s ---", page.MustInfo().URL)
	entries, err := page.Eval("() => { const logs = []; window.console.history = window.console.history || []; window.console.history.forEach(l => logs.push(l)); return logs; }")
	if err != nil {
		t.Logf("Error getting console logs: %v", err)
		// Fallback or try another method if console.history is not populated as expected
		// This part might need adjustment based on how `clientLogger` in index.html actually stores logs.
		// For now, assume it might populate a global array or use a more direct Rod method if available.
		return
	}

	if entries.Value.Str() == "null" || entries.Value.Str() == "" {
		t.Log("(No console logs captured via console.history or array is empty)")
		// Attempt to get logs via DevTools Protocol if above fails
		var consoleLogs []string
		done := page.Must каждой(func(e *proto.LogEntry) {
			args := []string{}
			for _, arg := range e.Args {
				if arg.Value != nil {
					valBytes, _ := json.Marshal(arg.Value)
					args = append(args, string(valBytes))
				} else if arg.Description != "" {
					args = append(args, arg.Description)
				} else {
					args = append(args, fmt.Sprintf("%v", arg.Type))
				}
			}
			logLine := fmt.Sprintf("[%s] %s: %s (Source: %s:%d)", e.Level, e.Type, strings.Join(args, " "), e.Source, e.LineNumber)
			consoleLogs = append(consoleLogs, logLine)
		})
		// Trigger a console log to ensure event listener is active
		page.MustEvaluate(rod.Eval(`() => console.log("--- Go test requesting browser logs ---")`))
		time.Sleep(200 * time.Millisecond) // Give a moment for logs to be collected
		done() // Stop listening

		if len(consoleLogs) > 0 {
			for _, logLine := range consoleLogs {
				t.Log(logLine)
			}
		} else {
			t.Log("(No console logs captured via DevTools Protocol listener either)")
		}
		return
	}
	
	var logs []map[string]interface{}
	if err := json.Unmarshal([]byte(entries.Value.Str()), &logs); err == nil {
		for _, logEntry := range logs {
			t.Logf("Browser Log: [%s] %v", logEntry["type"], logEntry["args"])
		}
	} else {
		t.Logf("Could not parse console.history: %s", entries.Value.Str())
	}
	t.Logf("--- End Browser Console Logs ---")
}


// MockSessionManager for JS tests that don't need full session manager logic
type MockSessionManager struct {
	logger broker.Logger
	mu sync.RWMutex
	pageToBroker map[string]string
	brokerToPage map[string]string
}

func NewMockSessionManager(logger broker.Logger) *MockSessionManager {
	return &MockSessionManager{
		logger: logger,
		pageToBroker: make(map[string]string),
		brokerToPage: make(map[string]string),
	}
}
func (m *MockSessionManager) Store(pageID, brokerID string) {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.pageToBroker[pageID] = brokerID
	m.brokerToPage[brokerID] = pageID
	m.logger.Debug("MockSessionManager: Stored %s -> %s", pageID, brokerID)
}
func (m *MockSessionManager) GetBrokerClientID(pageSessionID string) (string, bool) {
	m.mu.RLock()
	defer m.mu.RUnlock()
	id, found := m.pageToBroker[pageSessionID]
	m.logger.Debug("MockSessionManager: GetBrokerClientID for %s -> (%s, %v)", pageSessionID, id, found)
	return id, found
}
func (m *MockSessionManager) GetPageSessionID(brokerClientID string) (string, bool) {
	m.mu.RLock()
	defer m.mu.RUnlock()
	id, found := m.brokerToPage[brokerClientID]
	return id, found
}
// Add other methods if needed by API handler, or ensure API handler tests mock session manager directly.
```

This completes the update of the Go test files. I've focused on:
1.  Using `testify/assert` and `testify/require`.
2.  Aligning tests with the refactored method signatures and logic (e.g., context handling, error types).
3.  Making timeouts more generous for CI environments, especially for browser tests.
4.  Improving logging within tests for better debuggability.
5.  Adding the new tests from the test plan to `integration_test.go` where feasible with the existing `TestClient`/`TestServer` structure. Some highly specific failure simulations (like `TestWriteFailureTriggersDeregistration` needing direct manipulation of `ConnectionWriter` behavior) would require more intricate mocking or test harness adjustments.
6.  The `js_client_test.go` has been significantly updated to use the `index.html` which loads the refined `assets/dist/websocketmq.js`. It also includes more robust checks for UI elements and browser console logging on failure. A mock session manager is used to simplify setup for this specific test file, as the full session manager lifecycle is tested in integration tests.

The next logical step, if this were an interactive process, would be to run these tests and address any failures, which would likely involve fine-tuning both the application code and the tests themselves.